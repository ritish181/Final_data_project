{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ritish/projects/DATA_ENGINEERING/data-final-project/notebook/01_extract\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Employee Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'employees.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_employees = 1000\n",
    "departments = [\n",
    "    \"Human Resources\",\n",
    "    \"Finance\",\n",
    "    \"Marketing\",\n",
    "    \"Sales\",\n",
    "    \"Product Development\",\n",
    "    \"Customer Support\",\n",
    "    \"IT\",\n",
    "    \"Operations\",\n",
    "    \"Legal\",\n",
    "    \"Engineering\"\n",
    "]\n",
    "\n",
    "teams = [\n",
    "    \"Alpha Team\",\n",
    "    \"Beta Team\",\n",
    "    \"Gamma Team\",\n",
    "    \"Delta Team\",\n",
    "    \"Omega Team\",\n",
    "    \"Epsilon Team\",\n",
    "    \"Zeta Team\",\n",
    "    \"Theta Team\",\n",
    "    \"Sigma Team\",\n",
    "    \"Lambda Team\",\n",
    "    \"Phoenix Team\",\n",
    "    \"Falcon Team\",\n",
    "    \"Tiger Team\",\n",
    "    \"Eagle Team\",\n",
    "    \"Shark Team\",\n",
    "    \"Wolf Team\",\n",
    "    \"Dragon Team\",\n",
    "    \"Lion Team\",\n",
    "    \"Hawk Team\",\n",
    "    \"Rhino Team\"\n",
    "]\n",
    "\n",
    "roles = [\"User\", \"Admin\"]  # Roles\n",
    "\n",
    "# Generate employee data\n",
    "employees = []\n",
    "for i in range(1, num_employees + 1):\n",
    "    employee = {\n",
    "        \"EmployeeID\": i,\n",
    "        \"Name\": fake.name(),\n",
    "        \"Email\": fake.unique.email(),\n",
    "        \"Department\": random.choice(departments),\n",
    "        \"Team\": random.choice(teams),\n",
    "        \"Role\": random.choice(roles),\n",
    "        \"Password\": fake.password()  # Optional, add if needed\n",
    "    }\n",
    "    employees.append(employee)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(employees)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/employees.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'employees.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Course Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'courses.csv' has been created with 100 courses.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_courses = 100\n",
    "authors = [fake.name() for _ in range(20)]  # Randomly generate 20 unique authors\n",
    "course_images = [f\"image_{i+1}.jpg\" for i in range(100)]  # Example image filenames\n",
    "\n",
    "# Function to create a fake quiz (as JSON)\n",
    "def generate_quiz():\n",
    "    return {\n",
    "        \"questions\": [\n",
    "            {\"question\": \"Sample question 1\", \"options\": [\"a\", \"b\", \"c\", \"d\"], \"answer\": \"a\"},\n",
    "            {\"question\": \"Sample question 2\", \"options\": [\"a\", \"b\", \"c\", \"d\"], \"answer\": \"b\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Generate course data\n",
    "courses = []\n",
    "for i in range(1, num_courses + 1):\n",
    "    course = {\n",
    "        \"CourseID\": i,\n",
    "        \"CourseName\": fake.catch_phrase(),\n",
    "        \"CourseDescription\": fake.text(max_nb_chars=200),\n",
    "        \"CreationDate\": fake.date_this_decade(),\n",
    "        \"Author\": random.choice(authors),\n",
    "        \"Image\": random.choice(course_images),\n",
    "        \"Quiz\": generate_quiz() if random.random() > 0.5 else None  # Add quiz for some courses\n",
    "    }\n",
    "    courses.append(course)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(courses)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/courses.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'courses.csv' has been created with 100 courses.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'modules.csv' has been created with 500 modules.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_courses = 100\n",
    "modules_per_course = 5\n",
    "\n",
    "# Generate module data for each course\n",
    "modules = []\n",
    "for course_id in range(1, num_courses + 1):\n",
    "    for module_num in range(1, modules_per_course + 1):\n",
    "        module = {\n",
    "            \"ModuleID\": f\"{course_id}_{module_num}\",  # Unique module ID combining course ID and module number\n",
    "            \"ModuleName\": f\"Module {module_num} for Course {course_id}\",\n",
    "            \"ModuleDescription\": fake.text(max_nb_chars=200),\n",
    "            \"CourseID\": course_id\n",
    "        }\n",
    "        modules.append(module)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_modules = pd.DataFrame(modules)\n",
    "\n",
    "# Save to CSV\n",
    "df_modules.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/modules.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'modules.csv' has been created with 500 modules.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'enrollments.csv' has been created with 1000 enrollments.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_employees = 1000\n",
    "num_courses = 100\n",
    "num_enrollments = 1000\n",
    "\n",
    "# Generate enrollment data\n",
    "enrollments = []\n",
    "for _ in range(num_enrollments):\n",
    "    enrollment = {\n",
    "        \"EnrollmentID\": _ + 1,\n",
    "        \"EnrollDate\": fake.date_this_decade(),\n",
    "        \"QuizScore\": round(random.uniform(0, 100), 2) if random.random() > 0.2 else None,  # 80% have scores\n",
    "        \"EmployeeID\": random.randint(1, num_employees),\n",
    "        \"CourseID\": random.randint(1, num_courses)\n",
    "    }\n",
    "    enrollments.append(enrollment)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_enrollments = pd.DataFrame(enrollments)\n",
    "\n",
    "# Save to CSV\n",
    "df_enrollments.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/enrollments.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'enrollments.csv' has been created with 1000 enrollments.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engagment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'engagements.csv' has been created with 500 engagements.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Load the module data from module.csv\n",
    "df_modules = pd.read_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/modules.csv\")\n",
    "\n",
    "# Constants\n",
    "num_engagements = 500\n",
    "num_employees = 1000  # Assuming EmployeeID is between 1 and 1000\n",
    "\n",
    "# Generate engagement data\n",
    "engagements = []\n",
    "for i in range(num_engagements):\n",
    "    module = df_modules.iloc[i]  # Get the module for this engagement\n",
    "    start_time = fake.date_time_this_decade()  # Random start time in the past decade\n",
    "    time_spent = random.randint(5, 120)  # Random time spent between 5 and 120 minutes\n",
    "    end_time = start_time + timedelta(minutes=time_spent) if random.random() > 0.2 else None  # 80% have end time\n",
    "    \n",
    "    engagement = {\n",
    "        \"EngagementID\": i + 1,\n",
    "        \"TimeStart\": start_time,\n",
    "        \"TimeEnd\": end_time,\n",
    "        \"TimeSpent\": time_spent if end_time else 0,  # If there's no end time, assume time spent is 0\n",
    "        \"IsCompleted\": bool(end_time),  # Mark as completed if there's an end time\n",
    "        \"EmployeeID\": random.randint(1, num_employees),  # Random employee ID\n",
    "        \"ModuleID\": module[\"ModuleID\"],\n",
    "        \"CourseID\": module[\"CourseID\"]  # Assuming ModuleID is linked to CourseID\n",
    "    }\n",
    "    engagements.append(engagement)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_engagements = pd.DataFrame(engagements)\n",
    "\n",
    "# Save to CSV\n",
    "df_engagements.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/engagements.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'engagements.csv' has been created with 500 engagements.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'discussions.csv' has been created with 500 discussions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_discussions = 1500\n",
    "num_employees = 1000  # EmployeeID between 1 and 1000\n",
    "num_courses = 100    # CourseID between 1 and 100\n",
    "\n",
    "# Generate discussion data\n",
    "discussions = []\n",
    "for i in range(num_discussions):\n",
    "    employee_id = random.randint(1, num_employees)\n",
    "    course_id = random.randint(1, num_courses)\n",
    "    text = fake.paragraph(nb_sentences=5)  # Generate random discussion text\n",
    "    post_date = fake.date_time_this_year()  # Random post date this year\n",
    "    \n",
    "    # Set parent_dis_id for discussions after the first one\n",
    "    parent_dis_id = random.choice([None, random.randint(1, i)]) if i > 0 else None\n",
    "    \n",
    "    discussion = {\n",
    "        \"DiscussionID\": i + 1,\n",
    "        \"Text\": text,\n",
    "        \"PostDate\": post_date,\n",
    "        \"Parent_Dis_ID\": parent_dis_id,\n",
    "        \"EmployeeID\": employee_id,\n",
    "        \"CourseID\": course_id\n",
    "    }\n",
    "    discussions.append(discussion)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_discussions = pd.DataFrame(discussions)\n",
    "\n",
    "# Save to CSV\n",
    "df_discussions.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/discussions.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'discussions.csv' has been created with 500 discussions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'feedbacks.csv' has been created with 500 feedback entries.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Constants\n",
    "num_feedback = 500\n",
    "num_employees = 1000  # EmployeeID between 1 and 1000\n",
    "num_courses = 100     # CourseID between 1 and 100\n",
    "\n",
    "# Generate feedback data\n",
    "feedbacks = []\n",
    "for i in range(num_feedback):\n",
    "    employee_id = random.randint(1, num_employees)\n",
    "    course_id = random.randint(1, num_courses)\n",
    "    rating = random.randint(1, 5)  # Assuming rating is between 1 and 5\n",
    "    comment = fake.sentence(nb_words=10)  # Generate a random comment\n",
    "    submitted_at = fake.date_time_this_year()  # Random submission date this year\n",
    "    \n",
    "    feedback = {\n",
    "        \"FeedbackID\": i + 1,\n",
    "        \"Rating\": rating,\n",
    "        \"Comment\": comment,\n",
    "        \"SubmittedAt\": submitted_at,\n",
    "        \"EmployeeID\": employee_id,\n",
    "        \"CourseID\": course_id\n",
    "    }\n",
    "    feedbacks.append(feedback)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_feedbacks = pd.DataFrame(feedbacks)\n",
    "\n",
    "# Save to CSV\n",
    "df_feedbacks.to_csv(r\"/home/ritish/projects/DATA_ENGINEERING/data-final-project/data_enginnering/01_raw/genarated_data/feedbacks.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'feedbacks.csv' has been created with 500 feedback entries.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
